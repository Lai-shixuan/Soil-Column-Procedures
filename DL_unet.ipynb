{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from API_functions.DL import load_data, log, seed\n",
    "from API_functions import file_batch as fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter and log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_parameters = {\n",
    "    'seed': 42,\n",
    "\n",
    "    'Kfold': None,\n",
    "    'ratio': 0.2,\n",
    "\n",
    "    'model': 'efficientnet-b0',\n",
    "    'optimizer': 'adam',\n",
    "    'learning_rate':  0.001,\n",
    "    'batch_size': 32,\n",
    "    'loss_function': 'cross_entropy',\n",
    "\n",
    "    'n_epochs': 1000,\n",
    "    'patience': 50,\n",
    "}\n",
    "\n",
    "device = 'cuda'\n",
    "mylogger = log.Logger('all')\n",
    "\n",
    "seed.stablize_seed(my_parameters['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project=\"U-Net\",\n",
    "    name='4.extend train data',\n",
    "    config=my_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations and dataset\n",
    "transform_train = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=90),\n",
    "    v2.ToDtype(torch.float32)\n",
    "])\n",
    "\n",
    "transform_test = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    # v2.RandomHorizontalFlip(p=0.5),\n",
    "    # v2.RandomVerticalFlip(p=0.5),\n",
    "    # v2.RandomRotation(degrees=90),\n",
    "    v2.ToDtype(torch.float32)\n",
    "])\n",
    "\n",
    "transform_label = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.ToDtype(torch.float32)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(paths):\n",
    "    return [cv2.imread(p, cv2.IMREAD_GRAYSCALE) for p in paths]\n",
    "\n",
    "data_paths = fb.get_image_names('f:/3.Experimental_Data/DL_Data_raw/images/', None, 'png')\n",
    "labels_paths = fb.get_image_names('f:/3.Experimental_Data/DL_Data_raw/labels/', None, 'png')\n",
    "test_paths = fb.get_image_names('f:/3.Experimental_Data/DL_Data_raw/tests/', None, 'png')\n",
    "test_labels_paths = fb.get_image_names('f:/3.Experimental_Data/DL_Data_raw/test_labels/', None, 'png')\n",
    "\n",
    "data = load_images(data_paths)\n",
    "labels = load_images(labels_paths)\n",
    "tests = load_images(test_paths)\n",
    "test_labels = load_images(test_labels_paths)\n",
    "\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(data, labels, test_size=my_parameters['ratio'], random_state=my_parameters['seed'])\n",
    "\n",
    "train_dataset = load_data.my_Dataset(train_data, train_labels, transform=transform_train, label_transform=transform_label)\n",
    "val_dataset = load_data.my_Dataset(val_data, val_labels, transform=transform_test, label_transform=transform_label)\n",
    "test_dataset = load_data.my_Dataset(tests, test_labels, transform=transform_test, label_transform=transform_label)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=my_parameters['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=my_parameters['batch_size'], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=my_parameters['batch_size'], shuffle=False)\n",
    "\n",
    "print(f'len of train_data: {len(train_data)}, len of val_data: {len(val_data)}, len of test_data: {len(tests)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.dconv_down1 = DoubleConv(1, 64)\n",
    "        self.dconv_down2 = DoubleConv(64, 128)\n",
    "        self.dconv_down3 = DoubleConv(128, 256)\n",
    "        self.dconv_down4 = DoubleConv(256, 512)        \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = DoubleConv(256 + 512, 256)\n",
    "        self.dconv_up2 = DoubleConv(128 + 256, 128)\n",
    "        self.dconv_up1 = DoubleConv(64 + 128, 64)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, 1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "        \n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)\n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        x = self.conv_last(x)\n",
    "\n",
    "        x = torch.sigmoid(x)  # Apply sigmoid activation to the output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        # First, calculate the BCE loss\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        bce_loss = self.bce(inputs, targets)\n",
    "        \n",
    "        # Calculate Dice Loss\n",
    "        inputs_flat = inputs.view(-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs_flat * targets_flat).sum()\n",
    "        dice_loss = 1 - (2. * intersection + smooth) / (inputs_flat.sum() + targets_flat.sum() + smooth)\n",
    "        \n",
    "        # Combine BCE + Dice\n",
    "        return 0.5 * bce_loss + 0.5 * dice_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b2\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=my_parameters['learning_rate'])\n",
    "criterion = DiceBCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(my_parameters['n_epochs']):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    train_loss_mean = train_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "    val_loss_mean = val_loss / len(val_loader.dataset)\n",
    "    dict = {'train_loss': train_loss_mean, 'epoch': epoch, 'val_loss': val_loss_mean}\n",
    "    mylogger.log(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image, path):\n",
    "    \"\"\"Save a tensor as an image.\"\"\"\n",
    "    image = image.squeeze().cpu().numpy()\n",
    "    plt.imsave(path, image, cmap='gray')\n",
    "\n",
    "def test_model(model, test_loader, device='cuda'):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Turn off gradients to speed up this part\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = torch.sigmoid(outputs)  # Apply sigmoid to get values between 0 and 1\n",
    "            outputs = outputs > 0.5  # Threshold the probabilities to create a binary mask\n",
    "            \n",
    "            # Save output images\n",
    "            for idx, output in enumerate(outputs):\n",
    "                save_path = f'f:/3.Experimental_Data/DL_Data_raw/tests_inference4/002_ou_DongYing_{i*test_loader.batch_size + idx + 13635}_roi_selected.png'\n",
    "                save_image(output, save_path)\n",
    "\n",
    "            print(f'Processed batch {i+1}/{len(test_loader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from API_functions import file_compare as fc\n",
    "%matplotlib qt\n",
    "\n",
    "db = fc.ImageDatabase()\n",
    "# image_processor.add_result('pre_processed', tpi.user_threshold(image_processor.image, 160))\n",
    "zoom = fc.ZoomRegion(350, 450, 100, 200)\n",
    "db.add_additional_folder('f:/3.Experimental_Data/DL_Data_raw/tests/', 'test_set')\n",
    "db.add_additional_folder('f:/3.Experimental_Data/DL_Data_raw/tests_inference4/', 'test_inference')\n",
    "db.add_additional_folder('f:/3.Experimental_Data/DL_Data_raw/test_labels/', 'test_labels')\n",
    "image_processor = db.get_image_processor('002_ou_DongYing_13636_roi_selected.png')\n",
    "image_processor.show_images('test_set', 'test_inference', 'test_labels', zoom_region=zoom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpln39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
